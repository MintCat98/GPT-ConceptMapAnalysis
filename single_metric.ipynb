{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Graph Analysis\n",
    "### *(Individual Metrics)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sampling for entire analysis\n",
    "data_astronomy1 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강민철')\n",
    "data_astronomy2 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강지헌')\n",
    "\n",
    "# Drop an useless column\n",
    "data_astronomy1.drop('Name', axis=1, inplace=True)\n",
    "data_astronomy2.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Merge all dataframes into one dataframe:\n",
    "data_astronomy = pd.concat([data_astronomy1, data_astronomy2], axis=0)\n",
    "# data_astronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling1 = pd.read_excel('data/Sampling.xlsx', sheet_name='강지헌')\n",
    "data_sampling2 = pd.read_excel('data/Sampling.xlsx', sheet_name='신아현')\n",
    "data_sampling3 = pd.read_excel('data/Sampling.xlsx', sheet_name='신수연')\n",
    "\n",
    "data_sampling1.drop('Name', axis=1, inplace=True)\n",
    "data_sampling2.drop('Name', axis=1, inplace=True)\n",
    "data_sampling3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_sampling = pd.concat([data_sampling1, data_sampling2, data_sampling3], axis=0)\n",
    "# data_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_database1 = pd.read_excel('data/Database.xlsx', sheet_name='신수연')\n",
    "data_database2 = pd.read_excel('data/Database.xlsx', sheet_name='양연선')\n",
    "data_database3 = pd.read_excel('data/Database.xlsx', sheet_name='김나영')\n",
    "\n",
    "data_database1.drop('Name', axis=1, inplace=True)\n",
    "data_database2.drop('Name', axis=1, inplace=True)\n",
    "data_database3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_database = pd.concat([data_database1, data_database2, data_database3], axis=0)\n",
    "# data_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process graphs\n",
    "- 이름 형식: `<Domain>_<Modality>_<ID>`\n",
    "- Domain: `ASTRONOMY`, `SAMPLING`, `DATABASE`\n",
    "\n",
    "***참고사항**:\n",
    "    혹시 몰라 노드에 P.Knowledge를 추가로 라벨링해두었지만, 분석할 때는 그냥 df상에서도 충분히 가능해보임*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_astronomy = {}\n",
    "\n",
    "for id, sub_df in data_astronomy.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Astronomy_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_astronomy[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_sampling = {}\n",
    "\n",
    "for id, sub_df in data_sampling.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Sampling_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_sampling[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_database = {}\n",
    "\n",
    "for id, sub_df in data_database.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Database_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_database[graph_name] = G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for individual metrics\n",
    "1. `num_of_concepts`: 노드 개수와 동일\n",
    "2. `num_of_relationships`: 엣지 개수와 동일\n",
    "3. `num_of_hierarchies`\n",
    "4. `num_of_crosslinks`\n",
    "5. `cal_aspl`: Average shortest path length\n",
    "6. `cal_cc`: Clustering coefficient\n",
    "7. `cal_network_density`\n",
    "8. `cal_complexity`\n",
    "9. `get_level_deepest_hierarchy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_concepts(G):\n",
    "    return G.number_of_nodes()\n",
    "\n",
    "def num_of_relationships(G):\n",
    "    return G.number_of_edges()\n",
    "\n",
    "def num_of_hierarchies(G):\n",
    "    return nx.number_strongly_connected_components(G)\n",
    "\n",
    "def num_of_crosslinks(G):\n",
    "    return num_of_relationships(G) - num_of_concepts(G) + num_of_hierarchies(G)\n",
    "\n",
    "def cal_aspl(G):\n",
    "    try :\n",
    "        return nx.average_shortest_path_length(G)\n",
    "    except nx.exception.NetworkXError:\n",
    "        return 0\n",
    "\n",
    "def cal_cc(G):\n",
    "    return nx.average_clustering(G)\n",
    "\n",
    "def cal_network_density(G):\n",
    "    return nx.density(G)\n",
    "\n",
    "def cal_complexity(G):\n",
    "    E = G.number_of_edges()\n",
    "    N = G.number_of_nodes()\n",
    "    return (E / N) if (N > 0) else 0\n",
    "\n",
    "def get_level_deepest_hierarchy(G):\n",
    "    max_depth = 0\n",
    "    for component in nx.connected_components(G.to_undirected()):\n",
    "        subgraph = G.subgraph(component)\n",
    "        try:\n",
    "            depth = max(len(nx.shortest_path(subgraph, source, target)) for source in subgraph for target in subgraph)\n",
    "        except nx.NetworkXNoPath:\n",
    "            depth = 0\n",
    "        if depth > max_depth:\n",
    "            max_depth = depth\n",
    "    return max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis for individual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a new dataframe for the analysis\n",
    "columns = [\"ID\", \"num_of_concepts\", \"num_of_relationships\", \"num_of_hierarchies\", \"num_of_crosslinks\", \"ASPL\", \"CC\", \"network_density\", \"complexity\", \"level_of_deepest_hierarchy\"]\n",
    "df_astronomy = pd.DataFrame(columns=columns).set_index(\"ID\")\n",
    "df_sampling = pd.DataFrame(columns=columns).set_index(\"ID\")\n",
    "df_database = pd.DataFrame(columns=columns).set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_astronomy.items():\n",
    "    try:\n",
    "        df_astronomy.loc[graph_name] = [\n",
    "            num_of_concepts(G), \n",
    "            num_of_relationships(G), \n",
    "            num_of_hierarchies(G), \n",
    "            num_of_crosslinks(G), \n",
    "            cal_aspl(G), \n",
    "            cal_cc(G), \n",
    "            cal_network_density(G), \n",
    "            cal_complexity(G), \n",
    "            get_level_deepest_hierarchy(G)\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "df_astronomy.to_excel(\"result/Astronomy_indiv.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_sampling.items():\n",
    "    try:\n",
    "        df_sampling.loc[graph_name] = [\n",
    "            num_of_concepts(G), \n",
    "            num_of_relationships(G), \n",
    "            num_of_hierarchies(G), \n",
    "            num_of_crosslinks(G), \n",
    "            cal_aspl(G), \n",
    "            cal_cc(G), \n",
    "            cal_network_density(G), \n",
    "            cal_complexity(G), \n",
    "            get_level_deepest_hierarchy(G)\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "df_sampling.to_excel(\"result/Sampling_indiv.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_database.items():\n",
    "    try:\n",
    "        df_database.loc[graph_name] = [\n",
    "            num_of_concepts(G), \n",
    "            num_of_relationships(G), \n",
    "            num_of_hierarchies(G), \n",
    "            num_of_crosslinks(G), \n",
    "            cal_aspl(G), \n",
    "            cal_cc(G), \n",
    "            cal_network_density(G), \n",
    "            cal_complexity(G), \n",
    "            get_level_deepest_hierarchy(G)\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "df_database.to_excel(\"result/Database_indiv.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
