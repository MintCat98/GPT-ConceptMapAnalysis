{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Graph Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sampling for entire analysis\n",
    "data_astronomy1 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강민철')\n",
    "data_astronomy2 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강지헌')\n",
    "\n",
    "# Drop an useless column\n",
    "data_astronomy1.drop('Name', axis=1, inplace=True)\n",
    "data_astronomy2.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Merge all dataframes into one dataframe:\n",
    "data_astronomy = pd.concat([data_astronomy1, data_astronomy2], axis=0)\n",
    "data_astronomy.drop(data_astronomy.loc[data_astronomy['ID'] == 53].index[0], inplace=True)\n",
    "# data_astronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling1 = pd.read_excel('data/Sampling.xlsx', sheet_name='강지헌')\n",
    "data_sampling2 = pd.read_excel('data/Sampling.xlsx', sheet_name='신아현')\n",
    "data_sampling3 = pd.read_excel('data/Sampling.xlsx', sheet_name='신수연')\n",
    "\n",
    "data_sampling1.drop('Name', axis=1, inplace=True)\n",
    "data_sampling2.drop('Name', axis=1, inplace=True)\n",
    "data_sampling3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_sampling = pd.concat([data_sampling1, data_sampling2, data_sampling3], axis=0)\n",
    "# data_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_database1 = pd.read_excel('data/Database.xlsx', sheet_name='신수연')\n",
    "data_database2 = pd.read_excel('data/Database.xlsx', sheet_name='양연선')\n",
    "data_database3 = pd.read_excel('data/Database.xlsx', sheet_name='김나영')\n",
    "\n",
    "data_database1.drop('Name', axis=1, inplace=True)\n",
    "data_database2.drop('Name', axis=1, inplace=True)\n",
    "data_database3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_database = pd.concat([data_database1, data_database2, data_database3], axis=0)\n",
    "# data_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process graphs\n",
    "- 이름 형식: `<Domain>_<Modality>_<ID>`\n",
    "- Domain: `ASTRONOMY`, `SAMPLING`, `DATABASE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_astronomy = {}\n",
    "\n",
    "for id, sub_df in data_astronomy.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Astronomy_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_astronomy[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_sampling = {}\n",
    "\n",
    "for id, sub_df in data_sampling.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Sampling_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_sampling[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_database = {}\n",
    "\n",
    "for id, sub_df in data_database.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Database_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_database[graph_name] = G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process multi-graphs\n",
    "params:\n",
    "\n",
    "- `graphs_dict`: 도메인별 그래프 딕셔너리\n",
    "- `selected_G`: 멀티그래프 생성 시 제외할 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multigraph(graphs_dict, selected_G = None):\n",
    "    G = nx.MultiDiGraph()\n",
    "    for graph_name, graph in graphs_dict.items():\n",
    "        if graph_name != selected_G:\n",
    "            for node in graph.nodes():\n",
    "                G.add_node(node)\n",
    "            for edge in graph.edges():\n",
    "                G.add_edge(edge[0], edge[1])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multigraphs\n",
    "multigraph_astronomy_full = create_multigraph(graphs_astronomy)\n",
    "multigraph_sampling_full = create_multigraph(graphs_sampling)\n",
    "multigraph_database_full = create_multigraph(graphs_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for centrality metrics\n",
    "\n",
    "1. `cal_node_betweenness`\n",
    "2. `cal_node_closeness`\n",
    "3. `cal_node_degree`\n",
    "\n",
    "*(Get values from a multi-graph whose nodes accords with each individual graph, and then get a mean value with dividing the number of nodes of each graph.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centrality_average_for_subgraph(multi_graph: nx.MultiGraph, indiv_graph: nx.DiGraph, centrality_type: str) -> float:\n",
    "    # Convert the MultiGraph to a DiGraph to calculate centrality\n",
    "    multi_graph = nx.DiGraph(multi_graph)\n",
    "\n",
    "    # Calculate the specified centrality for all nodes in the multigraph\n",
    "    if centrality_type == 'betweenness':\n",
    "        centrality_values = nx.betweenness_centrality(multi_graph)\n",
    "    elif centrality_type == 'closeness':\n",
    "        centrality_values = nx.closeness_centrality(multi_graph)\n",
    "    elif centrality_type == 'degree':\n",
    "        centrality_values = nx.degree_centrality(multi_graph)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid centrality type. Choose from 'betweenness', 'closeness', or 'degree'.\")\n",
    "\n",
    "    # Initialize sum of centrality values\n",
    "    centrality_sum = 0\n",
    "\n",
    "    # Iterate over the nodes in the subgraph and sum the corresponding centrality values from the multigraph\n",
    "    for node in indiv_graph.nodes():\n",
    "        if node in centrality_values:\n",
    "            centrality_sum += centrality_values[node]\n",
    "\n",
    "    # Calculate the average by dividing by the number of nodes in the subgraph\n",
    "    average_centrality = centrality_sum / len(indiv_graph.nodes())\n",
    "\n",
    "    return average_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis for centrality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ID\", \"Betweenness\", \"Closeness\", \"Degree\"]\n",
    "cent_astronomy = pd.DataFrame(columns=columns).set_index(\"ID\")\n",
    "cent_sampling = pd.DataFrame(columns=columns).set_index(\"ID\")\n",
    "cent_database = pd.DataFrame(columns=columns).set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_astronomy.items():\n",
    "    try:\n",
    "        cent_astronomy.loc[graph_name] = [\n",
    "            calculate_centrality_average_for_subgraph(multigraph_astronomy_full, G, \"betweenness\"),\n",
    "            calculate_centrality_average_for_subgraph(multigraph_astronomy_full, G, \"closeness\"),\n",
    "            calculate_centrality_average_for_subgraph(multigraph_astronomy_full, G, \"degree\")\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "cent_astronomy.to_excel(\"result/Astronomy_central.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_sampling.items():\n",
    "    try:\n",
    "        cent_sampling.loc[graph_name] = [\n",
    "            calculate_centrality_average_for_subgraph(multigraph_sampling_full, G, \"betweenness\"),\n",
    "            calculate_centrality_average_for_subgraph(multigraph_sampling_full, G, \"closeness\"),\n",
    "            calculate_centrality_average_for_subgraph(multigraph_sampling_full, G, \"degree\")\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "cent_sampling.to_excel(\"result/Sampling_central.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_database.items():\n",
    "    try:\n",
    "        cent_database.loc[graph_name] = [\n",
    "            calculate_centrality_average_for_subgraph(multigraph_database_full, G, \"betweenness\"),\n",
    "            calculate_centrality_average_for_subgraph(multigraph_database_full, G, \"closeness\"),\n",
    "            calculate_centrality_average_for_subgraph(multigraph_database_full, G, \"degree\")\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "cent_database.to_excel(\"result/Database_central.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
