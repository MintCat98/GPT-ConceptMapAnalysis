{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Graph Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sampling for entire analysis\n",
    "data_astronomy1 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강민철')\n",
    "data_astronomy2 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강지헌')\n",
    "\n",
    "# Drop an useless column\n",
    "data_astronomy1.drop('Name', axis=1, inplace=True)\n",
    "data_astronomy2.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Merge all dataframes into one dataframe:\n",
    "data_astronomy = pd.concat([data_astronomy1, data_astronomy2], axis=0)\n",
    "data_astronomy.drop(data_astronomy.loc[data_astronomy['ID'] == 53].index[0], inplace=True)\n",
    "# data_astronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling1 = pd.read_excel('data/Sampling.xlsx', sheet_name='강지헌')\n",
    "data_sampling2 = pd.read_excel('data/Sampling.xlsx', sheet_name='신아현')\n",
    "data_sampling3 = pd.read_excel('data/Sampling.xlsx', sheet_name='신수연')\n",
    "\n",
    "data_sampling1.drop('Name', axis=1, inplace=True)\n",
    "data_sampling2.drop('Name', axis=1, inplace=True)\n",
    "data_sampling3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_sampling = pd.concat([data_sampling1, data_sampling2, data_sampling3], axis=0)\n",
    "# data_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_database1 = pd.read_excel('data/Database.xlsx', sheet_name='신수연')\n",
    "data_database2 = pd.read_excel('data/Database.xlsx', sheet_name='양연선')\n",
    "data_database3 = pd.read_excel('data/Database.xlsx', sheet_name='김나영')\n",
    "\n",
    "data_database1.drop('Name', axis=1, inplace=True)\n",
    "data_database2.drop('Name', axis=1, inplace=True)\n",
    "data_database3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_database = pd.concat([data_database1, data_database2, data_database3], axis=0)\n",
    "# data_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process graphs\n",
    "- 이름 형식: `<Domain>_<Modality>_<ID>`\n",
    "- Domain: `ASTRONOMY`, `SAMPLING`, `DATABASE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_astronomy = {}\n",
    "\n",
    "for id, sub_df in data_astronomy.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Astronomy_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_astronomy[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_sampling = {}\n",
    "\n",
    "for id, sub_df in data_sampling.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Sampling_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_sampling[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_database = {}\n",
    "\n",
    "for id, sub_df in data_database.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Database_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_database[graph_name] = G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process multi-graphs\n",
    "params:\n",
    "\n",
    "- `graphs_dict`: 도메인별 그래프 딕셔너리\n",
    "- `selected_G`: 멀티그래프 생성 시 제외할 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multigraph(graphs_dict, selected_G = None):\n",
    "    G = nx.MultiDiGraph()\n",
    "    for graph_name, graph in graphs_dict.items():\n",
    "        if graph_name != selected_G:\n",
    "            for node in graph.nodes():\n",
    "                G.add_node(node)\n",
    "            for edge in graph.edges():\n",
    "                G.add_edge(edge[0], edge[1])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multigraphs\n",
    "multigraph_astronomy_full = create_multigraph(graphs_astronomy)\n",
    "multigraph_sampling_full = create_multigraph(graphs_sampling)\n",
    "multigraph_database_full = create_multigraph(graphs_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for centrality metrics\n",
    "(Multi-graph를 digraph로 변환하여 계산)\n",
    "\n",
    "1. `cal_node_betweeness`\n",
    "2. `cal_node_closeness`\n",
    "3. `cal_node_degree`\n",
    "\n",
    "*(각각 상위 3개의 항목을 추출함)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_node_betweenness(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.betweenness_centrality(G)\n",
    "    top_3_nodes = sorted(values.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    return dict(top_3_nodes)\n",
    "\n",
    "def cal_node_closeness(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.closeness_centrality(G)\n",
    "    top_3_nodes = sorted(values.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    return dict(top_3_nodes)\n",
    "\n",
    "def cal_node_degree(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.degree_centrality(G)\n",
    "    top_3_nodes = sorted(values.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    return dict(top_3_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis for centrality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling method\n",
    "def fill_df(graph_name, graph):\n",
    "    global df_centrality\n",
    "    \n",
    "    betweenness_top_3 = cal_node_betweenness(graph)\n",
    "    closeness_top_3 = cal_node_closeness(graph)\n",
    "    degree_top_3 = cal_node_degree(graph)\n",
    "    row = {'Graph': graph_name}\n",
    "    \n",
    "    for i, (node, value) in enumerate(betweenness_top_3.items(), 1):\n",
    "        row[('Betweenness', f'node{i}')] = node\n",
    "        row[('Betweenness', f'value{i}')] = value\n",
    "    \n",
    "    for i, (node, value) in enumerate(closeness_top_3.items(), 1):\n",
    "        row[('Closeness', f'node{i}')] = node\n",
    "        row[('Closeness', f'value{i}')] = value\n",
    "    \n",
    "    for i, (node, value) in enumerate(degree_top_3.items(), 1):\n",
    "        row[('Degree', f'node{i}')] = node\n",
    "        row[('Degree', f'value{i}')] = value\n",
    "\n",
    "    df_centrality.loc[len(df_centrality)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.MultiIndex.from_product(\n",
    "    [['Betweenness', 'Closeness', 'Degree'], \n",
    "     ['node1', 'value1', 'node2', 'value2', 'node3', 'value3']]\n",
    ")\n",
    "df_centrality = pd.DataFrame(columns=['Graph'] + columns.tolist())\n",
    "\n",
    "fill_df('Astronomy', multigraph_astronomy_full)\n",
    "fill_df('Sampling', multigraph_sampling_full)\n",
    "fill_df('Database', multigraph_database_full)\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "df_centrality.to_excel(\"result/All_centrality.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
