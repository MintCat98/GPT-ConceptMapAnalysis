{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Graph Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sampling for entire analysis\n",
    "data_astronomy1 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강민철')\n",
    "data_astronomy2 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강지헌')\n",
    "\n",
    "# Drop an useless column\n",
    "data_astronomy1.drop('Name', axis=1, inplace=True)\n",
    "data_astronomy2.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Merge all dataframes into one dataframe:\n",
    "data_astronomy = pd.concat([data_astronomy1, data_astronomy2], axis=0)\n",
    "data_astronomy.drop(data_astronomy.loc[data_astronomy['ID'] == 53].index[0], inplace=True)\n",
    "# data_astronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling1 = pd.read_excel('data/Sampling.xlsx', sheet_name='강지헌')\n",
    "data_sampling2 = pd.read_excel('data/Sampling.xlsx', sheet_name='신아현')\n",
    "data_sampling3 = pd.read_excel('data/Sampling.xlsx', sheet_name='신수연')\n",
    "\n",
    "data_sampling1.drop('Name', axis=1, inplace=True)\n",
    "data_sampling2.drop('Name', axis=1, inplace=True)\n",
    "data_sampling3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_sampling = pd.concat([data_sampling1, data_sampling2, data_sampling3], axis=0)\n",
    "# data_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_database1 = pd.read_excel('data/Database.xlsx', sheet_name='신수연')\n",
    "data_database2 = pd.read_excel('data/Database.xlsx', sheet_name='양연선')\n",
    "data_database3 = pd.read_excel('data/Database.xlsx', sheet_name='김나영')\n",
    "\n",
    "data_database1.drop('Name', axis=1, inplace=True)\n",
    "data_database2.drop('Name', axis=1, inplace=True)\n",
    "data_database3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_database = pd.concat([data_database1, data_database2, data_database3], axis=0)\n",
    "# data_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process graphs\n",
    "- 이름 형식: `<Domain>_<Modality>_<ID>`\n",
    "- Domain: `ASTRONOMY`, `SAMPLING`, `DATABASE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_astronomy = {}\n",
    "\n",
    "for id, sub_df in data_astronomy.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Astronomy_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_astronomy[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_sampling = {}\n",
    "\n",
    "for id, sub_df in data_sampling.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Sampling_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_sampling[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_database = {}\n",
    "\n",
    "for id, sub_df in data_database.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Database_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_database[graph_name] = G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process multi-graphs\n",
    "params:\n",
    "\n",
    "- `graphs_dict`: 도메인별 그래프 딕셔너리\n",
    "- `selected_G`: 멀티그래프 생성 시 제외할 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multigraph(graphs_dict, selected_G = None):\n",
    "    G = nx.MultiDiGraph()\n",
    "    for graph_name, graph in graphs_dict.items():\n",
    "        if graph_name != selected_G:\n",
    "            for node in graph.nodes():\n",
    "                G.add_node(node)\n",
    "            for edge in graph.edges():\n",
    "                G.add_edge(edge[0], edge[1])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multigraphs\n",
    "multigraph_astronomy_full = create_multigraph(graphs_astronomy)\n",
    "multigraph_sampling_full = create_multigraph(graphs_sampling)\n",
    "multigraph_database_full = create_multigraph(graphs_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for centrality metrics\n",
    "(Multi-graph를 digraph로 변환하여 계산)\n",
    "\n",
    "1. `cal_node_betweeness`\n",
    "2. `cal_node_closeness`\n",
    "3. `cal_node_degree`\n",
    "\n",
    "*(각각 상위 3개의 항목을 추출함)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_node_betweenness(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.betweenness_centrality(G)\n",
    "    top_3_nodes = sorted(values.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    return dict(top_3_nodes)\n",
    "\n",
    "def cal_node_closeness(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.closeness_centrality(G)\n",
    "    top_3_nodes = sorted(values.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    return dict(top_3_nodes)\n",
    "\n",
    "def cal_node_degree(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.degree_centrality(G)\n",
    "    top_3_nodes = sorted(values.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    return dict(top_3_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis for centrality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling method\n",
    "def fill_df(graph_name, graph):\n",
    "    global df_centrality\n",
    "    \n",
    "    betweenness_top_3 = cal_node_betweenness(graph)\n",
    "    closeness_top_3 = cal_node_closeness(graph)\n",
    "    degree_top_3 = cal_node_degree(graph)\n",
    "    row = {'Graph': graph_name}\n",
    "    \n",
    "    for i, (node, value) in enumerate(betweenness_top_3.items(), 1):\n",
    "        row[('Betweenness', f'node{i}')] = node\n",
    "        row[('Betweenness', f'value{i}')] = value\n",
    "    \n",
    "    for i, (node, value) in enumerate(closeness_top_3.items(), 1):\n",
    "        row[('Closeness', f'node{i}')] = node\n",
    "        row[('Closeness', f'value{i}')] = value\n",
    "    \n",
    "    for i, (node, value) in enumerate(degree_top_3.items(), 1):\n",
    "        row[('Degree', f'node{i}')] = node\n",
    "        row[('Degree', f'value{i}')] = value\n",
    "\n",
    "    df_centrality.loc[len(df_centrality)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.MultiIndex.from_product(\n",
    "    [['Betweenness', 'Closeness', 'Degree'], \n",
    "     ['node1', 'value1', 'node2', 'value2', 'node3', 'value3']]\n",
    ")\n",
    "df_centrality = pd.DataFrame(columns=['Graph'] + columns.tolist())\n",
    "\n",
    "fill_df('Astronomy', multigraph_astronomy_full)\n",
    "fill_df('Sampling', multigraph_sampling_full)\n",
    "fill_df('Database', multigraph_database_full)\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "df_centrality.to_excel(\"result/All_centrality.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for consensus metrics\n",
    "\n",
    "1. `cal_edge_consensus`\n",
    "2. `cal_subgraph_coverage`\n",
    "3. `cal_collective_shortest_path`\n",
    "4. `cal_communicability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_edge_consensus(student_graph: nx.Graph, multi_graph: nx.MultiDiGraph) -> float:\n",
    "    total_edges = len(student_graph.edges())\n",
    "    matching_edges = 0\n",
    "    \n",
    "    for edge in student_graph.edges():\n",
    "        multi_edge_count = multi_graph.number_of_edges(edge[0], edge[1])\n",
    "        if multi_edge_count > 0:\n",
    "            matching_edges += multi_edge_count\n",
    "    \n",
    "    return matching_edges / total_edges if total_edges > 0 else 0\n",
    "\n",
    "def cal_subgraph_coverage(student_graph: nx.Graph, multi_graph: nx.MultiDiGraph) -> float:\n",
    "    total_multi_edges = len(multi_graph.edges())\n",
    "    matching_edges = 0\n",
    "    \n",
    "    for edge in student_graph.edges():\n",
    "        if multi_graph.has_edge(*edge):\n",
    "            matching_edges += 1\n",
    "    \n",
    "    return matching_edges / total_multi_edges if total_multi_edges > 0 else 0\n",
    "\n",
    "def cal_collective_shortest_path(student_graph: nx.Graph, multi_graph: nx.MultiDiGraph) -> float:\n",
    "    aggregate_shortest_paths = dict(nx.all_pairs_dijkstra_path_length(multi_graph))\n",
    "    student_shortest_paths = dict(nx.all_pairs_dijkstra_path_length(student_graph))\n",
    "    total_difference = 0\n",
    "    count = 0\n",
    "    \n",
    "    for node, paths in student_shortest_paths.items():\n",
    "        for target, length in paths.items():\n",
    "            if node in aggregate_shortest_paths and target in aggregate_shortest_paths[node]:\n",
    "                total_difference += abs(length - aggregate_shortest_paths[node][target])\n",
    "                count += 1\n",
    "    \n",
    "    return total_difference / count if count > 0 else float('inf')\n",
    "\n",
    "def cal_communicability(student_graph: nx.Graph, multi_graph: nx.MultiDiGraph) -> float:\n",
    "    undirected_student_graph = student_graph.to_undirected()\n",
    "    undirected_multi_graph = nx.Graph(multi_graph)\n",
    "\n",
    "    student_communicability = nx.communicability_exp(undirected_student_graph)\n",
    "    multi_communicability = nx.communicability_exp(undirected_multi_graph)\n",
    "\n",
    "    total_difference = 0\n",
    "    count = 0\n",
    "    \n",
    "    for node, comm_dict in student_communicability.items():\n",
    "        for target, comm_value in comm_dict.items():\n",
    "            if node in multi_communicability and target in multi_communicability[node]:\n",
    "                difference = abs(comm_value - multi_communicability[node][target])\n",
    "                total_difference += np.log1p(difference)  # Logarithm smoothing\n",
    "                count += 1\n",
    "    \n",
    "    return total_difference / count if count > 0 else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis for consensus metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a new dataframe for the analysis\n",
    "columns = [\"ID\", \"edge_consensus\", \"subgraph_coverage\", \"collective_shortest_path\", \"communicability\"]\n",
    "consen_astronomy = pd.DataFrame(columns=columns).set_index(\"ID\")\n",
    "consen_sampling = pd.DataFrame(columns=columns).set_index(\"ID\")\n",
    "consen_database = pd.DataFrame(columns=columns).set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_astronomy.items():\n",
    "    try:\n",
    "        consen_astronomy.loc[graph_name] = [\n",
    "            cal_edge_consensus(G, multigraph_astronomy_full),\n",
    "            cal_subgraph_coverage(G, multigraph_astronomy_full),\n",
    "            cal_collective_shortest_path(G, multigraph_astronomy_full),\n",
    "            cal_communicability(G, multigraph_astronomy_full)\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "consen_astronomy.to_excel(\"result/Astronomy_consen.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_sampling.items():\n",
    "    try:\n",
    "        consen_sampling.loc[graph_name] = [\n",
    "            cal_edge_consensus(G, multigraph_sampling_full),\n",
    "            cal_subgraph_coverage(G, multigraph_sampling_full),\n",
    "            cal_collective_shortest_path(G, multigraph_sampling_full),\n",
    "            cal_communicability(G, multigraph_sampling_full)\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "consen_sampling.to_excel(\"result/Sampling_consen.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_name, G in graphs_database.items():\n",
    "    try:\n",
    "        consen_database.loc[graph_name] = [\n",
    "            cal_edge_consensus(G, multigraph_database_full),\n",
    "            cal_subgraph_coverage(G, multigraph_database_full),\n",
    "            cal_collective_shortest_path(G, multigraph_database_full),\n",
    "            cal_communicability(G, multigraph_database_full)\n",
    "        ]\n",
    "    except nx.NetworkXNoPath as e:\n",
    "        print(f\"Path error at {graph_name}: {e}\")\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "consen_database.to_excel(\"result/Database_consen.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
