{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Graph Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sampling for entire analysis\n",
    "data_astronomy1 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강민철')\n",
    "data_astronomy2 = pd.read_excel('data/Astronomy.xlsx', sheet_name='강지헌')\n",
    "\n",
    "# Drop an useless column\n",
    "data_astronomy1.drop('Name', axis=1, inplace=True)\n",
    "data_astronomy2.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Merge all dataframes into one dataframe:\n",
    "data_astronomy = pd.concat([data_astronomy1, data_astronomy2], axis=0)\n",
    "data_astronomy.drop(data_astronomy.loc[data_astronomy['ID'] == 53].index[0], inplace=True)\n",
    "# data_astronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling1 = pd.read_excel('data/Sampling.xlsx', sheet_name='강지헌')\n",
    "data_sampling2 = pd.read_excel('data/Sampling.xlsx', sheet_name='신아현')\n",
    "data_sampling3 = pd.read_excel('data/Sampling.xlsx', sheet_name='신수연')\n",
    "\n",
    "data_sampling1.drop('Name', axis=1, inplace=True)\n",
    "data_sampling2.drop('Name', axis=1, inplace=True)\n",
    "data_sampling3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_sampling = pd.concat([data_sampling1, data_sampling2, data_sampling3], axis=0)\n",
    "# data_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_database1 = pd.read_excel('data/Database.xlsx', sheet_name='신수연')\n",
    "data_database2 = pd.read_excel('data/Database.xlsx', sheet_name='양연선')\n",
    "data_database3 = pd.read_excel('data/Database.xlsx', sheet_name='김나영')\n",
    "\n",
    "data_database1.drop('Name', axis=1, inplace=True)\n",
    "data_database2.drop('Name', axis=1, inplace=True)\n",
    "data_database3.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "data_database = pd.concat([data_database1, data_database2, data_database3], axis=0)\n",
    "# data_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process graphs\n",
    "- 이름 형식: `<Domain>_<Modality>_<ID>`\n",
    "- Domain: `ASTRONOMY`, `SAMPLING`, `DATABASE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_astronomy = {}\n",
    "\n",
    "for id, sub_df in data_astronomy.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Astronomy_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_astronomy[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_sampling = {}\n",
    "\n",
    "for id, sub_df in data_sampling.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Sampling_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_sampling[graph_name] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_database = {}\n",
    "\n",
    "for id, sub_df in data_database.groupby('ID'):\n",
    "    # New graph object\n",
    "    graph_name = f\"Database_{sub_df['Mod.'].iloc[0]}_{sub_df['ID'].iloc[0]}\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in sub_df.iterrows():\n",
    "        start_node = row['Start']\n",
    "        if pd.notna(row['End']):\n",
    "            end_nodes = [end_node.rstrip() for end_node in row['End'].split(',')]\n",
    "            for end_node in end_nodes:\n",
    "                G.add_edge(start_node, end_node)\n",
    "        # Add p.knowledge labels:  O -> 1(true)  |  X -> 0(false)\n",
    "        try:\n",
    "            G.nodes[start_node]['P.Knowledge'] = 1 if row['P.Knowledge'] == 'O' else 0\n",
    "        except KeyError:\n",
    "            G.add_node(start_node)\n",
    "            G.nodes[start_node]['P.Knowledge'] = 0\n",
    "    \n",
    "    # Save the graph\n",
    "    graphs_database[graph_name] = G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process multi-graphs\n",
    "params:\n",
    "\n",
    "- `graphs_dict`: 도메인별 그래프 딕셔너리\n",
    "- `selected_G`: 멀티그래프 생성 시 제외할 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multigraph(graphs_dict, selected_G = None):\n",
    "    G = nx.MultiDiGraph()\n",
    "    for graph_name, graph in graphs_dict.items():\n",
    "        if graph_name != selected_G:\n",
    "            for node in graph.nodes():\n",
    "                G.add_node(node)\n",
    "            for edge in graph.edges():\n",
    "                G.add_edge(edge[0], edge[1])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multigraphs\n",
    "multigraph_astronomy_full = create_multigraph(graphs_astronomy)\n",
    "multigraph_sampling_full = create_multigraph(graphs_sampling)\n",
    "multigraph_database_full = create_multigraph(graphs_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for centrality metrics\n",
    "(Multi-graph를 digraph로 변환하여 계산)\n",
    "\n",
    "1. `cal_node_betweeness`\n",
    "2. `cal_node_closeness`\n",
    "3. `cal_node_degree`\n",
    "\n",
    "*=> 각각 최댓값과 최댓값을 갖는 노드를 return함*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_node_betweenness(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.betweenness_centrality(G)\n",
    "    max_node = max(values, key=values.get)\n",
    "    return {max_node: values[max_node]}\n",
    "\n",
    "def cal_node_closeness(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.closeness_centrality(G)\n",
    "    max_node = max(values, key=values.get)\n",
    "    return {max_node: values[max_node]}\n",
    "\n",
    "def cal_node_degree(G):\n",
    "    G = nx.DiGraph(G)\n",
    "    values = nx.degree_centrality(G)\n",
    "    max_node = max(values, key=values.get)\n",
    "    return {max_node: values[max_node]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis for centrality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling method\n",
    "def fill_df(graph_name: str, G: nx.MultiGraph):\n",
    "    global df_centrality\n",
    "    betweenness_result = cal_node_betweenness(G)\n",
    "    closeness_result = cal_node_closeness(G)\n",
    "    degree_result = cal_node_degree(G)\n",
    "    \n",
    "    new_row = pd.DataFrame({\n",
    "        'Graph': [graph_name],\n",
    "        ('Betweenness', 'node'): [list(betweenness_result.keys())[0]],\n",
    "        ('Betweenness', 'value'): [list(betweenness_result.values())[0]],\n",
    "        ('Closeness', 'node'): [list(closeness_result.keys())[0]],\n",
    "        ('Closeness', 'value'): [list(closeness_result.values())[0]],\n",
    "        ('Degree', 'node'): [list(degree_result.keys())[0]],\n",
    "        ('Degree', 'value'): [list(degree_result.values())[0]],\n",
    "    }, index=[0])\n",
    "    \n",
    "    df_centrality = pd.concat([df_centrality, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most important node in each graph\n",
    "columns = pd.MultiIndex.from_product([['Betweenness', 'Closeness', 'Degree'], ['node', 'value']])\n",
    "df_centrality = pd.DataFrame(columns=['Graph'] + columns.tolist())\n",
    "\n",
    "fill_df('Astronomy', multigraph_astronomy_full)\n",
    "fill_df('Sampling', multigraph_sampling_full)\n",
    "fill_df('Database', multigraph_database_full)\n",
    "\n",
    "# Save the result to excel file\n",
    "# ❗WARNING❗ It will automatically overwrite the existing file!!!\n",
    "df_centrality.to_excel(\"result/All_centrality.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
